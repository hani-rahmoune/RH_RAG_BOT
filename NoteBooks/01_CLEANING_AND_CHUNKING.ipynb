{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ePlp3Xe5q3yf",
        "outputId": "59ce2213-6978-4195-a97e-5a10aa7e771e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20251230 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-5.4.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (3.0)\n",
            "Downloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.4.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20251230 pdfplumber-0.11.9 pypdfium2-5.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QYBEFuKXnGKn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dir_path =\"/content/drive/MyDrive/projects/chu_chat_bot\"\n",
        "data_path = \"/content/drive/MyDrive/projects/chu_chat_bot/data\"\n",
        "os.makedirs(dir_path, exist_ok = True )\n",
        "os.makedirs(data_path, exist_ok = True )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib as path\n",
        "import pdfplumber\n",
        "\n",
        "\n",
        "def pdf_to_pages(file_path): #list of dicts\n",
        "  file_path = path.Path(file_path)\n",
        "  pages = []\n",
        "  with pdfplumber.open(str(file_path)) as pdf :\n",
        "    for i , page in enumerate(pdf.pages , start = 1): #page 1 stays 1 for convenience\n",
        "      pages.append({\n",
        "          \"source\" : file_path.name,\n",
        "          \"page\" : i,\n",
        "          \"text\" : page.extract_text() or \"\"\n",
        "      })\n",
        "  return pages\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "skl_T3jAnw-U"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re #cleaning biblio\n",
        "\n",
        "import re\n",
        "\n",
        "def text_cleaning(s):\n",
        "    if not s:\n",
        "        return \"\"\n",
        "\n",
        "    s = s.replace(\"\\x00\", \" \").replace(\"\\xa0\", \" \") #null bytes\n",
        "    s = s.replace(\"\\t\", \" \") # tab -> 1 space\n",
        "    s = re.sub(r\"-\\n\", \"\", s) #exemple : bigwo- then back line -od -> bigword\n",
        "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s) # more than 2 newlines to 2 lines\n",
        "    s = re.sub(r\"[ ]{2,}\", \" \", s)#spaces to one space\n",
        "\n",
        "    return s.strip() # superfluous spaces at the end or beginning\n"
      ],
      "metadata": {
        "id": "JjMZcbVtsLXG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_clean(pdf_path , min_char = 50):\n",
        "  pages = pdf_to_pages(pdf_path)\n",
        "  for page in pages :\n",
        "    page[\"text\"] = text_cleaning(page[\"text\"])\n",
        "\n",
        "  pages = [ p for p in pages if len(p[\"text\"])>min_char] # drop pages where page has less than 50 character\n",
        "  return pages\n"
      ],
      "metadata": {
        "id": "M4kVILcIvGfK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text , length = 1200 , overlap = 200) :\n",
        "  chunks = []\n",
        "  start = 0\n",
        "  while start <len(text) :\n",
        "    end = min(start + length , len(text))\n",
        "    chunk = (text[start:end]).strip()\n",
        "    if chunk :\n",
        "      chunks.append(chunk)\n",
        "    if end == len(text) :\n",
        "      break\n",
        "    start = max(end - overlap,0)\n",
        "  return chunks\n"
      ],
      "metadata": {
        "id": "np-kPmvSwZ_X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_clean_and_chunk(pdf_path,tier: int = 2, doc_date: str = None):\n",
        "  chunks = []\n",
        "  pages = load_and_clean(pdf_path)\n",
        "  for page in pages :\n",
        "    for i , chunk in enumerate(chunk_text(page[\"text\"]),start = 1):\n",
        "      chunks.append({\n",
        "          \"source\" : page[\"source\"],\n",
        "          \"page\" : page[\"page\"],\n",
        "          \"chunk\" : i,\n",
        "          \"chunk_id\": f\"{page['source']}_p{page['page']}_c{i}\", #unqiue id\n",
        "          \"tier\": tier,\n",
        "          \"date\": doc_date,\n",
        "          \"text\": chunk_text\n",
        "      })\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "a1q7BKgmyUQc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_to_all_pdfs(pdf_dir_path) :\n",
        "  chunks = []\n",
        "  for pdf_path in pdf_dir_path.glob(\"*.pdf\"):\n",
        "    chunks.extend(load_and_clean_and_chunk(pdf_path))\n",
        "  return chunks\n",
        ""
      ],
      "metadata": {
        "id": "rFbIa1o2zHP4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def save_jsonl(chunks,data_path):\n",
        "  out_dir = path.Path(data_path)\n",
        "  out_dir.mkdir(exist_ok = True)\n",
        "  with open(data_path + \"/chunks.jsonl\",\"w\" ,encoding= \"utf-8\") as f :\n",
        "    for chunk in chunks :\n",
        "      f.write(json.dumps(chunk,ensure_ascii=False) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "cfs6VpMi0Rkg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_pipe_line(pdf_dir_path,data_path):\n",
        "  chunks = apply_to_all_pdfs(pdf_dir_path)\n",
        "  save_jsonl(chunks,data_path)\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "r1br5_xZ0ttc"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}
